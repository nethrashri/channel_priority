{
 "cells": [
  {
   "cell_type": "raw",
   "id": "627ffe8d-e9cb-4714-9f75-7821689b8345",
   "metadata": {},
   "source": [
    "1. Preprocessing\n",
    "This step involves:\n",
    "\n",
    "Aggregating the data.\n",
    "Normalizing values.\n",
    "Creating sequences for time series forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7081780c-ae04-42e5-adcf-0d5b3ac94eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (36526, 24, 16), y_train shape: (36526, 16)\n",
      "X_test shape: (9132, 24, 16), y_test shape: (9132, 16)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"user_activity_pattern_updated_v6_30_nov.csv\")  # Replace with your file path\n",
    "\n",
    "# Convert timestamp to datetime and sort the data\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data = data.sort_values(by='timestamp')\n",
    "\n",
    "# Aggregate data for hourly usage\n",
    "data_agg = data.groupby(['timestamp', 'service_group', 'service_name'])['usage_minutes'].sum().reset_index()\n",
    "\n",
    "# Pivot the data to create a time series for each service\n",
    "pivoted_data = data_agg.pivot_table(\n",
    "    index='timestamp', columns=['service_group', 'service_name'], values='usage_minutes', fill_value=0\n",
    ")\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(pivoted_data)\n",
    "\n",
    "# Create sequences for GRU\n",
    "def create_sequences(data, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i + sequence_length])\n",
    "        y.append(data[i + sequence_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Set sequence length (e.g., 24 hours)\n",
    "sequence_length = 24\n",
    "X, y = create_sequences(scaled_data, sequence_length)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Print shapes for verification\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21fadbca-55ca-4e2d-b742-f8184abe6e52",
   "metadata": {},
   "source": [
    "2. Build and Train GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3ea83-56e6-40d8-a379-a45350f5b45f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 06:28:48.442036: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2024-12-02 06:28:48.442125: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-12-02 06:28:48.442147: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-12-02 06:28:48.442398: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-02 06:28:48.442850: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "# Define the GRU model\n",
    "model = Sequential([\n",
    "    GRU(64, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    GRU(64, activation='relu', return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(X_train.shape[2])  # Output layer with the number of features (services)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=10,  # Adjust epochs as needed\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c9ddbc5-867b-47e1-84f9-8bc1a4e57f30",
   "metadata": {},
   "source": [
    "3. Predict Usage for the Next 15 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f4db13-7f3f-496c-a103-bf2a218d7ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate future predictions\n",
    "def predict_future(model, input_data, future_steps):\n",
    "    predictions = []\n",
    "    current_input = input_data[-1]  # Start from the last available data\n",
    "    for _ in range(future_steps):\n",
    "        prediction = model.predict(current_input[np.newaxis, :, :])\n",
    "        predictions.append(prediction[0])\n",
    "        current_input = np.vstack([current_input[1:], prediction])  # Update the input with the prediction\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Predict the next 15 days (15 * 24 = 360 hourly steps)\n",
    "future_steps = 15 * 24\n",
    "future_predictions = predict_future(model, X_test, future_steps)\n",
    "\n",
    "# Inverse transform the predictions to get the actual scale\n",
    "future_predictions_rescaled = scaler.inverse_transform(future_predictions)\n",
    "\n",
    "# Generate future timestamps\n",
    "last_timestamp = pivoted_data.index[-1]\n",
    "future_timestamps = pd.date_range(start=last_timestamp, periods=future_steps + 1, freq='H')[1:]\n",
    "\n",
    "# Combine predictions into a DataFrame\n",
    "future_df = pd.DataFrame(future_predictions_rescaled, index=future_timestamps, columns=pivoted_data.columns)\n",
    "future_df.reset_index(inplace=True)\n",
    "future_df.rename(columns={\"index\": \"timestamp\"}, inplace=True)\n",
    "\n",
    "# Save predictions to CSV\n",
    "future_df.to_csv(\"future_predictions.csv\", index=False)\n",
    "print(\"Future predictions saved to 'future_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3bd1185-02c6-4905-9fad-7b2b23fe770d",
   "metadata": {},
   "source": [
    "4. Visualize Actual vs Predicted Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d872cf8-152b-4eec-a397-3d6adf9c22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual vs predicted usage trends (hourly)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Select a service group and name (e.g., Gaming - Fortnite)\n",
    "service_group = \"Gaming\"\n",
    "service_name = \"Fortnite\"\n",
    "\n",
    "# Plot actual data\n",
    "plt.plot(\n",
    "    pivoted_data.index[-len(y_test):],\n",
    "    scaler.inverse_transform(y_test)[:, pivoted_data.columns.get_loc((service_group, service_name))],\n",
    "    label=\"Actual\",\n",
    "    marker='o'\n",
    ")\n",
    "\n",
    "# Plot predicted data\n",
    "plt.plot(\n",
    "    future_timestamps,\n",
    "    future_predictions_rescaled[:, pivoted_data.columns.get_loc((service_group, service_name))],\n",
    "    label=\"Predicted\",\n",
    "    linestyle='--'\n",
    ")\n",
    "\n",
    "plt.title(f\"Actual vs Predicted Usage for {service_name} ({service_group})\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Usage (Minutes)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2e5d79b-cc22-4d92-a9a0-61b2e0b7e03a",
   "metadata": {},
   "source": [
    "5. Analyze Trends\n",
    "To understand hourly, weekly, and monthly patterns, aggregate predictions accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e6ad6-7273-4906-a577-9cdf8554d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly trends\n",
    "hourly_trends = future_df.groupby(future_df['timestamp'].dt.hour).sum()\n",
    "\n",
    "# Weekly trends\n",
    "weekly_trends = future_df.groupby(future_df['timestamp'].dt.dayofweek).sum()\n",
    "\n",
    "# Monthly trends\n",
    "monthly_trends = future_df.groupby(future_df['timestamp'].dt.month).sum()\n",
    "\n",
    "# Plot hourly trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "hourly_trends.sum(axis=1).plot(kind='bar')\n",
    "plt.title(\"Predicted Hourly Usage Trends\")\n",
    "plt.xlabel(\"Hour of the Day\")\n",
    "plt.ylabel(\"Total Usage (Minutes)\")\n",
    "plt.show()\n",
    "\n",
    "# Plot weekly trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "weekly_trends.sum(axis=1).plot(kind='bar')\n",
    "plt.title(\"Predicted Weekly Usage Trends\")\n",
    "plt.xlabel(\"Day of the Week\")\n",
    "plt.ylabel(\"Total Usage (Minutes)\")\n",
    "plt.show()\n",
    "\n",
    "# Plot monthly trends\n",
    "plt.figure(figsize=(10, 6))\n",
    "monthly_trends.sum(axis=1).plot(kind='bar')\n",
    "plt.title(\"Predicted Monthly Usage Trends\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Total Usage (Minutes)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97569666-8816-4fec-9e0b-044e681ac273",
   "metadata": {},
   "source": [
    "Preprocessed Dataset:\n",
    "\n",
    "Ready for GRU input, with scaled and normalized sequences.\n",
    "GRU Model:\n",
    "\n",
    "Predicts user service usage for the next 15 days.\n",
    "Visualizations:\n",
    "\n",
    "Actual vs predicted trends for selected services.\n",
    "Aggregated hourly, weekly, and monthly usage patterns.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35de7564-1486-4d8c-a0fe-452bd7decaaf",
   "metadata": {},
   "source": [
    "\n",
    "To visualize trends by service, we can focus on specific service_group and service_name combinations. This allows us to break down usage patterns and predictions for each service and its group. Below is the code for visualizing actual and predicted trends for specific services.\n",
    "\n",
    "Code for Service-Specific Trends Visualization\n",
    "1. Plot Actual vs Predicted Trends for a Specific Service\n",
    "Weâ€™ll visualize the usage for a selected service, showing how the actual data compares to predictions over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f0af7-957c-4d0c-b9f9-bb19e3f7b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize trends for a specific service\n",
    "def plot_service_trends(service_group, service_name, y_test, future_predictions_rescaled, future_timestamps, pivoted_data):\n",
    "    # Find the column index for the selected service\n",
    "    service_index = pivoted_data.columns.get_loc((service_group, service_name))\n",
    "    \n",
    "    # Extract actual and predicted data for the service\n",
    "    actual_data = scaler.inverse_transform(y_test)[:, service_index]\n",
    "    predicted_data = future_predictions_rescaled[:, service_index]\n",
    "    \n",
    "    # Plot actual vs predicted data\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(\n",
    "        pivoted_data.index[-len(actual_data):],\n",
    "        actual_data,\n",
    "        label=\"Actual\",\n",
    "        marker='o',\n",
    "        color=\"blue\"\n",
    "    )\n",
    "    plt.plot(\n",
    "        future_timestamps,\n",
    "        predicted_data,\n",
    "        label=\"Predicted\",\n",
    "        linestyle='--',\n",
    "        color=\"orange\"\n",
    "    )\n",
    "    plt.title(f\"Actual vs Predicted Usage for {service_name} ({service_group})\")\n",
    "    plt.xlabel(\"Timestamp\")\n",
    "    plt.ylabel(\"Usage (Minutes)\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Example: Plot trends for \"Gaming\" and \"Fortnite\"\n",
    "plot_service_trends(\"Gaming\", \"Fortnite\", y_test, future_predictions_rescaled, future_timestamps, pivoted_data)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc9fa7aa-c98b-420e-85f8-e2c9786bfca4",
   "metadata": {},
   "source": [
    "2. Plot Aggregated Usage for All Services in a Group\n",
    "We can aggregate usage across all services within a group to observe trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8c1488-0a7e-442f-8829-1e17fa9988b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize aggregated trends for a service group\n",
    "def plot_group_trends(service_group, y_test, future_predictions_rescaled, future_timestamps, pivoted_data):\n",
    "    # Get column indices for the selected group\n",
    "    group_columns = [col for col in pivoted_data.columns if col[0] == service_group]\n",
    "    group_indices = [pivoted_data.columns.get_loc(col) for col in group_columns]\n",
    "    \n",
    "    # Aggregate actual and predicted data for the group\n",
    "    actual_data = scaler.inverse_transform(y_test)[:, group_indices].sum(axis=1)\n",
    "    predicted_data = future_predictions_rescaled[:, group_indices].sum(axis=1)\n",
    "    \n",
    "    # Plot aggregated trends\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(\n",
    "        pivoted_data.index[-len(actual_data):],\n",
    "        actual_data,\n",
    "        label=\"Actual\",\n",
    "        marker='o',\n",
    "        color=\"blue\"\n",
    "    )\n",
    "    plt.plot(\n",
    "        future_timestamps,\n",
    "        predicted_data,\n",
    "        label=\"Predicted\",\n",
    "        linestyle='--',\n",
    "        color=\"orange\"\n",
    "    )\n",
    "    plt.title(f\"Actual vs Predicted Aggregated Usage for {service_group}\")\n",
    "    plt.xlabel(\"Timestamp\")\n",
    "    plt.ylabel(\"Usage (Minutes)\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Example: Plot trends for the \"Gaming\" group\n",
    "plot_group_trends(\"Gaming\", y_test, future_predictions_rescaled, future_timestamps, pivoted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2855bea4-cdc8-4523-b1ef-df5f44c617d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Hourly, Weekly, and Monthly Trends for a Service\n",
    "This code aggregates the predictions for a specific service to show trends by time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c200b377-f743-4541-8500-eda614ac61d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hourly, weekly, and monthly trends for a service\n",
    "def plot_time_aggregated_trends(service_group, service_name, future_predictions_rescaled, future_timestamps, pivoted_data):\n",
    "    # Find the column index for the selected service\n",
    "    service_index = pivoted_data.columns.get_loc((service_group, service_name))\n",
    "    \n",
    "    # Extract predicted data for the service\n",
    "    predicted_data = future_predictions_rescaled[:, service_index]\n",
    "    predicted_df = pd.DataFrame({\"timestamp\": future_timestamps, \"usage\": predicted_data})\n",
    "    \n",
    "    # Aggregate by hour, week, and month\n",
    "    predicted_df['hour'] = predicted_df['timestamp'].dt.hour\n",
    "    predicted_df['day_of_week'] = predicted_df['timestamp'].dt.dayofweek\n",
    "    predicted_df['month'] = predicted_df['timestamp'].dt.month\n",
    "    \n",
    "    # Hourly trends\n",
    "    hourly_trends = predicted_df.groupby('hour')['usage'].sum()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    hourly_trends.plot(kind='bar', color='skyblue')\n",
    "    plt.title(f\"Hourly Predicted Usage for {service_name} ({service_group})\")\n",
    "    plt.xlabel(\"Hour of the Day\")\n",
    "    plt.ylabel(\"Total Usage (Minutes)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Weekly trends\n",
    "    weekly_trends = predicted_df.groupby('day_of_week')['usage'].sum()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    weekly_trends.plot(kind='bar', color='green')\n",
    "    plt.title(f\"Weekly Predicted Usage for {service_name} ({service_group})\")\n",
    "    plt.xlabel(\"Day of the Week\")\n",
    "    plt.ylabel(\"Total Usage (Minutes)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Monthly trends\n",
    "    monthly_trends = predicted_df.groupby('month')['usage'].sum()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    monthly_trends.plot(kind='bar', color='orange')\n",
    "    plt.title(f\"Monthly Predicted Usage for {service_name} ({service_group})\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Total Usage (Minutes)\")\n",
    "    plt.show()\n",
    "\n",
    "# Example: Plot hourly, weekly, and monthly trends for \"Gaming - Fortnite\"\n",
    "plot_time_aggregated_trends(\"Gaming\", \"Fortnite\", future_predictions_rescaled, future_timestamps, pivoted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99d829-22e6-4e17-b69c-ee2a088c7034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c4366-2ecf-4fb1-b2f2-e8066bac2811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9fadf9-b4b0-40b4-ad6e-b84f63fd2748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
